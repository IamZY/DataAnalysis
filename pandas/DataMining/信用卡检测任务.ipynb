{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams[\"font.sans-serif\"] = [\"SimHei\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_class = pd.value_counts(data[\"Class\"],sort = True).sort_index()\n",
    "print(count_class)\n",
    "count_class.plot(kind = \"bar\")\n",
    "plt.title(\"Found class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据标准化处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# reshape 一维数组化二维数组\n",
    "data[\"normAmount\"] = StandardScaler().fit_transform(data[\"Amount\"].values.reshape(-1,1))\n",
    "\n",
    "data = data.drop([\"Time\",\"Amount\"],axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984\n"
     ]
    }
   ],
   "source": [
    "# 0和1一样多  over sample\n",
    "# 0和1一样少  under sample\n",
    "# 下采样方案\n",
    "\n",
    "X = data.iloc[:,data.columns != \"Class\"]\n",
    "y = data.iloc[:,data.columns == \"Class\"]\n",
    "\n",
    "# 得到所有异常样本\n",
    "number_records_fraud = len(data[data.Class == 1])\n",
    "fraud_indices = np.array(data[data.Class == 1].index)\n",
    "\n",
    "# 得到所有正常样本的索引\n",
    "normal_indices = data[data.Class == 0].index\n",
    "\n",
    "# 在正常样本中随机取出指定个数的样本 并取其索引\n",
    "random_normal_indices = np.random.choice(normal_indices,number_records_fraud,replace = False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "# 有了正常样本和异常样本后把他们的索引都拿到手\n",
    "under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n",
    "\n",
    "under_sample_data = data.iloc[under_sample_indices,:]\n",
    "\n",
    "X_undersample = under_sample_data.iloc[:,under_sample_data.columns != \"Class\"]\n",
    "y_undersample = under_sample_data.iloc[:,under_sample_data.columns == \"Class\"]\n",
    "\n",
    "print(len(under_sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199364\n",
      "85443\n",
      "284807\n",
      "688\n",
      "296\n",
      "984\n"
     ]
    }
   ],
   "source": [
    "# 数据集的划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 整个数据集进行划分 random_state=0保证测试集相同\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 0)\n",
    "\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_train) + len(X_test))\n",
    "\n",
    "# 下采样数据集进行划分\n",
    "X_train_undersample,X_test_undersample,y_train_undersample,y_test_undersample = train_test_split(X_undersample,y_undersample,test_size = 0.3,random_state = 0)\n",
    "\n",
    "print(len(X_train_undersample))\n",
    "print(len(X_test_undersample))\n",
    "print(len(X_train_undersample) + len(X_test_undersample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逻辑回归模型\n",
    "# Recall = TP/(TP+FN)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,recall_score,classification_report\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printing_Kfold_scores(x_train_data,y_train_data):\n",
    "    fold = KFold(5,shuffle=False) \n",
    "\n",
    "    # 定义不同力度的正则化惩罚力度\n",
    "    c_param_range = [0.01,0.1,1,10,100]\n",
    "    # 展示结果用的表格\n",
    "    results_table = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Mean recall score'])\n",
    "    results_table['C_parameter'] = c_param_range\n",
    "\n",
    "    # k-fold 表示K折的交叉验证，这里会得到两个索引集合: 训练集 = indices[0], 验证集 = indices[1]\n",
    "    j = 0\n",
    "    #循环遍历不同的参数\n",
    "    for c_param in c_param_range:\n",
    "        print('-------------------------------------------')\n",
    "        print('正则化惩罚力度: ', c_param)\n",
    "        print('-------------------------------------------')\n",
    "        print('')\n",
    "\n",
    "        recall_accs = []\n",
    "        \n",
    "        #一步步分解来执行交叉验证\n",
    "        for iteration, indices in enumerate(fold.split(y_train_data),start=1):\n",
    "\n",
    "            # 指定算法模型，并且给定参数\n",
    "            lr = LogisticRegression(C = c_param, penalty = 'l1')\n",
    "\n",
    "            # 训练模型，注意索引不要给错了，训练的时候一定传入的是训练集，所以X和Y的索引都是0\n",
    "            lr.fit(x_train_data.iloc[indices[0],:],y_train_data.iloc[indices[0],:].values.ravel())\n",
    "\n",
    "            # 建立好模型后，预测模型结果，这里用的就是验证集，索引为1\n",
    "            y_pred_undersample = lr.predict(x_train_data.iloc[indices[1],:].values)\n",
    "\n",
    "            # 有了预测结果之后就可以来进行评估了，这里recall_score需要传入预测值和真实值。\n",
    "            recall_acc = recall_score(y_train_data.iloc[indices[1],:].values,y_pred_undersample)\n",
    "            # 一会还要算平均，所以把每一步的结果都先保存起来。\n",
    "            recall_accs.append(recall_acc)\n",
    "            print('Iteration ', iteration,': 召回率 = ', recall_acc)\n",
    "\n",
    "        # 当执行完所有的交叉验证后，计算平均结果\n",
    "        results_table.loc[j,'Mean recall score'] = np.mean(recall_accs)\n",
    "        j += 1\n",
    "        print('')\n",
    "        print('平均召回率 ', np.mean(recall_accs))\n",
    "        print('')\n",
    "        \n",
    "    #找到最好的参数，哪一个Recall高，自然就是最好的了。\n",
    "    best_c = results_table.loc[results_table['Mean recall score'].astype('float32').idxmax()]['C_parameter']\n",
    "    \n",
    "    # 打印最好的结果\n",
    "    print('*********************************************************************************')\n",
    "    print('效果最好的模型所选参数 = ', best_c)\n",
    "    print('*********************************************************************************')\n",
    "    \n",
    "    return best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "正则化惩罚力度:  0.01\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : 召回率 =  0.9315068493150684\n",
      "Iteration  2 : 召回率 =  0.9178082191780822\n",
      "Iteration  3 : 召回率 =  1.0\n",
      "Iteration  4 : 召回率 =  0.972972972972973\n",
      "Iteration  5 : 召回率 =  0.9545454545454546\n",
      "\n",
      "平均召回率  0.9553666992023157\n",
      "\n",
      "-------------------------------------------\n",
      "正则化惩罚力度:  0.1\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : 召回率 =  0.8356164383561644\n",
      "Iteration  2 : 召回率 =  0.863013698630137\n",
      "Iteration  3 : 召回率 =  0.9491525423728814\n",
      "Iteration  4 : 召回率 =  0.9324324324324325\n",
      "Iteration  5 : 召回率 =  0.8939393939393939\n",
      "\n",
      "平均召回率  0.8948309011462019\n",
      "\n",
      "-------------------------------------------\n",
      "正则化惩罚力度:  1\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : 召回率 =  0.8493150684931506\n",
      "Iteration  2 : 召回率 =  0.8904109589041096\n",
      "Iteration  3 : 召回率 =  0.9661016949152542\n",
      "Iteration  4 : 召回率 =  0.9459459459459459\n",
      "Iteration  5 : 召回率 =  0.8939393939393939\n",
      "\n",
      "平均召回率  0.9091426124395708\n",
      "\n",
      "-------------------------------------------\n",
      "正则化惩罚力度:  10\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : 召回率 =  0.8767123287671232\n",
      "Iteration  2 : 召回率 =  0.8904109589041096\n",
      "Iteration  3 : 召回率 =  0.9661016949152542\n",
      "Iteration  4 : 召回率 =  0.9459459459459459\n",
      "Iteration  5 : 召回率 =  0.9090909090909091\n",
      "\n",
      "平均召回率  0.9176523675246685\n",
      "\n",
      "-------------------------------------------\n",
      "正则化惩罚力度:  100\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : 召回率 =  0.8767123287671232\n",
      "Iteration  2 : 召回率 =  0.8904109589041096\n",
      "Iteration  3 : 召回率 =  0.9661016949152542"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration  4 : 召回率 =  0.9459459459459459\n",
      "Iteration  5 : 召回率 =  0.9242424242424242\n",
      "\n",
      "平均召回率  0.9206826705549714\n",
      "\n",
      "*********************************************************************************\n",
      "效果最好的模型所选参数 =  0.01\n",
      "*********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "best_c = printing_Kfold_scores(X_train_undersample,y_train_undersample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
