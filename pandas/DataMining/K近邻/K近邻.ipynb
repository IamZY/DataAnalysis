{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习-K近邻\n",
    "\n",
    "### Airbnb 房价预测任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.png\" style=\"width:800px;height:480px;float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3723, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>$160.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$350.00</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$50.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$95.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>$50.00</td>\n",
       "      <td>7</td>\n",
       "      <td>1125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accommodates  bedrooms  bathrooms  beds    price  minimum_nights  \\\n",
       "0             4       1.0        1.0   2.0  $160.00               1   \n",
       "1             6       3.0        3.0   3.0  $350.00               2   \n",
       "2             1       1.0        2.0   1.0   $50.00               2   \n",
       "3             2       1.0        1.0   1.0   $95.00               1   \n",
       "4             4       1.0        1.0   1.0   $50.00               7   \n",
       "\n",
       "   maximum_nights  number_of_reviews  \n",
       "0            1125                  0  \n",
       "1              30                 65  \n",
       "2            1125                  1  \n",
       "3            1125                  0  \n",
       "4            1125                  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features = ['accommodates','bedrooms','bathrooms','beds','price','minimum_nights','maximum_nights','number_of_reviews']\n",
    "\n",
    "dc_listings = pd.read_csv('listings.csv')\n",
    "\n",
    "dc_listings = dc_listings[features]\n",
    "\n",
    "print(dc_listings.shape)\n",
    "\n",
    "dc_listings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据特征：\n",
    "\n",
    "* accommodates: 可以容纳的旅客\n",
    "* bedrooms: 卧室的数量\n",
    "* bathrooms: 厕所的数量\n",
    "* beds: 床的数量\n",
    "* price: 每晚的费用\n",
    "* minimum_nights: 客人最少租了几天\n",
    "* maximum_nights: 客人最多租了几天\n",
    "* number_of_reviews: 评论的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module pandas.io.parsers:\n",
      "\n",
      "read_csv(filepath_or_buffer, sep=',', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, iterator=False, chunksize=None, compression='infer', thousands=None, decimal=b'.', lineterminator=None, quotechar='\"', quoting=0, escapechar=None, comment=None, encoding=None, dialect=None, tupleize_cols=None, error_bad_lines=True, warn_bad_lines=True, skipfooter=0, doublequote=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None)\n",
      "    Read CSV (comma-separated) file into DataFrame\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the `online docs for IO Tools\n",
      "    <http://pandas.pydata.org/pandas-docs/stable/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, pathlib.Path, py._path.local.LocalPath or any \\\n",
      "    object with a read() method (such as a file handle or StringIO)\n",
      "        The string could be a URL. Valid URL schemes include http, ftp, s3, and\n",
      "        file. For file URLs, a host is expected. For instance, a local file could\n",
      "        be file://localhost/path/to/table.csv\n",
      "    sep : str, default ','\n",
      "        Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used and automatically detect the separator by Python's builtin sniffer\n",
      "        tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
      "        different from ``'\\s+'`` will be interpreted as regular expressions and\n",
      "        will also force the use of the Python parsing engine. Note that regex\n",
      "        delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``\n",
      "    delimiter : str, default ``None``\n",
      "        Alternative argument name for sep.\n",
      "    delim_whitespace : boolean, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'\\t'``) will be\n",
      "        used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to True, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "    \n",
      "        .. versionadded:: 0.18.1 support for the Python parser.\n",
      "    \n",
      "    header : int or list of ints, default 'infer'\n",
      "        Row number(s) to use as the column names, and the start of the\n",
      "        data.  Default behavior is to infer the column names: if no names\n",
      "        are passed the behavior is identical to ``header=0`` and column\n",
      "        names are inferred from the first line of the file, if column\n",
      "        names are passed explicitly then the behavior is identical to\n",
      "        ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "        replace existing names. The header can be a list of integers that\n",
      "        specify row locations for a multi-index on the columns\n",
      "        e.g. [0,1,3]. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example is skipped). Note that this\n",
      "        parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so header=0 denotes the first line of\n",
      "        data rather than the first line of the file.\n",
      "    names : array-like, default None\n",
      "        List of column names to use. If file contains no header row, then you\n",
      "        should explicitly pass header=None. Duplicates in this list will cause\n",
      "        a ``UserWarning`` to be issued.\n",
      "    index_col : int or sequence or False, default None\n",
      "        Column to use as the row labels of the DataFrame. If a sequence is given, a\n",
      "        MultiIndex is used. If you have a malformed file with delimiters at the end\n",
      "        of each line, you might consider index_col=False to force pandas to _not_\n",
      "        use the first column as the index (row names)\n",
      "    usecols : list-like or callable, default None\n",
      "        Return a subset of the columns. If list-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in `names` or\n",
      "        inferred from the document header row(s). For example, a valid list-like\n",
      "        `usecols` parameter would be [0, 1, 2] or ['foo', 'bar', 'baz']. Element\n",
      "        order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "        To instantiate a DataFrame from ``data`` with element order preserved use\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
      "        in ``['foo', 'bar']`` order or\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "        for ``['bar', 'foo']`` order.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to True. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    squeeze : boolean, default False\n",
      "        If the parsed data only contains one column then return a Series\n",
      "    prefix : str, default None\n",
      "        Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
      "    mangle_dupe_cols : boolean, default True\n",
      "        Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    dtype : Type name or dict of column -> type, default None\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
      "        Use `str` or `object` together with suitable `na_values` settings\n",
      "        to preserve and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    engine : {'c', 'python'}, optional\n",
      "        Parser engine to use. The C engine is faster while the python engine is\n",
      "        currently more feature-complete.\n",
      "    converters : dict, default None\n",
      "        Dict of functions for converting values in certain columns. Keys can either\n",
      "        be integers or column labels\n",
      "    true_values : list, default None\n",
      "        Values to consider as True\n",
      "    false_values : list, default None\n",
      "        Values to consider as False\n",
      "    skipinitialspace : boolean, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : list-like or integer or callable, default None\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "        at the start of the file.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning True if the row should be skipped and False otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with engine='c')\n",
      "    nrows : int, default None\n",
      "        Number of rows of file to read. Useful for reading pieces of large files\n",
      "    na_values : scalar, str, list-like, or dict, default None\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values.  By default the following values are interpreted as\n",
      "        NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', 'N/A', 'NA', 'NULL', 'NaN', 'n/a', 'nan',\n",
      "        'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default NaN values when parsing the data.\n",
      "        Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "          is appended to the default NaN values used for parsing.\n",
      "        * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "          the default NaN values are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "          the NaN values specified `na_values` are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "          strings will be parsed as NaN.\n",
      "    \n",
      "        Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "        `na_values` parameters will be ignored.\n",
      "    na_filter : boolean, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file\n",
      "    verbose : boolean, default False\n",
      "        Indicate number of NA values placed in non-numeric columns\n",
      "    skip_blank_lines : boolean, default True\n",
      "        If True, skip over blank lines rather than interpreting as NaN values\n",
      "    parse_dates : boolean or list of ints or names or list of lists or dict, default False\n",
      "    \n",
      "        * boolean. If True -> try parsing the index.\n",
      "        * list of ints or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call result\n",
      "          'foo'\n",
      "    \n",
      "        If a column or index contains an unparseable date, the entire column or\n",
      "        index will be returned unaltered as an object data type. For non-standard\n",
      "        datetime parsing, use ``pd.to_datetime`` after ``pd.read_csv``\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : boolean, default False\n",
      "        If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
      "        format of the datetime strings in the columns, and if it can be inferred,\n",
      "        switch to a faster method of parsing them. In some cases this can increase\n",
      "        the parsing speed by 5-10x.\n",
      "    keep_date_col : boolean, default False\n",
      "        If True and `parse_dates` specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : function, default None\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    dayfirst : boolean, default False\n",
      "        DD/MM format dates, international and European format\n",
      "    iterator : boolean, default False\n",
      "        Return TextFileReader object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    chunksize : int, default None\n",
      "        Return TextFileReader object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "    compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and\n",
      "        `filepath_or_buffer` is path-like, then detect compression from the\n",
      "        following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
      "        decompression). If using 'zip', the ZIP file must contain only one data\n",
      "        file to be read in. Set to None for no decompression.\n",
      "    \n",
      "        .. versionadded:: 0.18.1 support for 'zip' and 'xz' compression.\n",
      "    \n",
      "    thousands : str, default None\n",
      "        Thousands separator\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point (e.g. use ',' for European data).\n",
      "    float_precision : string, default None\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are `None` for the ordinary converter,\n",
      "        `high` for the high-precision converter, and `round_trip` for the\n",
      "        round-trip converter.\n",
      "    lineterminator : str (length 1), default None\n",
      "        Character to break file into lines. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        The character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the delimiter and it will be ignored.\n",
      "    quoting : int or csv.QUOTE_* instance, default 0\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "        QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "    doublequote : boolean, default ``True``\n",
      "       When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive quotechar elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), default None\n",
      "        One-character string used to escape delimiter when quoting is QUOTE_NONE.\n",
      "    comment : str, default None\n",
      "        Indicates remainder of line should not be parsed. If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter `header` but not by\n",
      "        `skiprows`. For example, if ``comment='#'``, parsing\n",
      "        ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
      "        treated as the header.\n",
      "    encoding : str, default None\n",
      "        Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_\n",
      "    dialect : str or csv.Dialect instance, default None\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
      "        `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
      "        override values, a ParserWarning will be issued. See csv.Dialect\n",
      "        documentation for more details.\n",
      "    tupleize_cols : boolean, default False\n",
      "        .. deprecated:: 0.21.0\n",
      "           This argument will be removed and will always convert to MultiIndex\n",
      "    \n",
      "        Leave a list of tuples on columns as is (default is to convert to\n",
      "        a MultiIndex on the columns)\n",
      "    error_bad_lines : boolean, default True\n",
      "        Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "        default cause an exception to be raised, and no DataFrame will be returned.\n",
      "        If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
      "        returned.\n",
      "    warn_bad_lines : boolean, default True\n",
      "        If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "        \"bad line\" will be output.\n",
      "    low_memory : boolean, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set False, or specify the type with the `dtype` parameter.\n",
      "        Note that the entire file is read into a single DataFrame regardless,\n",
      "        use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
      "        (Only valid with C parser)\n",
      "    memory_map : boolean, default False\n",
      "        If a filepath is provided for `filepath_or_buffer`, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    result : DataFrame or TextParser\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (help(pd.read_csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如果我有一个1个房间的房子，我能租多少钱呢？\n",
    "讲道理，咱是不是得去看看1个房间的别人都租到多少钱啊！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2.png\" style=\"width:600px;height:230px;float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K代表我们的候选对象个数，也就是找和我房间数量最相近的其他房子的价格"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K近邻原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"3.png\" style=\"width:600px;height:330px;float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设我们的数据源中只有5条信息，现在我想针对我的房子（只有一个房间）来定一个价格。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"4.png\" style=\"width:600px;height:330px;float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里假设我们选择的K=3，也就是选3个跟我最相近的房源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"5.png\" style=\"width:600px;height:330px;float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再综合考虑这三个我就得到了我的房子大概能值多钱啦！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 距离的定义\n",
    "如何才能知道哪些数据样本跟我最相近呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"6.png\" style=\"width:400px;height:80px;float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中Q1到Qn是一条数据的所有特征信息，P1到Pn是另一条数据的所有特征信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设我们的房子有3个房间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      461\n",
       "1     2294\n",
       "2      503\n",
       "3      279\n",
       "4       35\n",
       "5       73\n",
       "6       17\n",
       "7       22\n",
       "8        7\n",
       "9       12\n",
       "10       2\n",
       "11       4\n",
       "12       6\n",
       "13       8\n",
       "Name: distance, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "our_acc_value = 3\n",
    "\n",
    "dc_listings['distance'] = np.abs(dc_listings.accommodates - our_acc_value)\n",
    "dc_listings.distance.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们只有了绝对值来计算，和我们距离为0的（同样数量的房间）有461个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample操作可以得到洗牌后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2645     $75.00\n",
       "2825    $120.00\n",
       "2145     $90.00\n",
       "2541     $50.00\n",
       "3349    $105.00\n",
       "Name: price, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_listings = dc_listings.sample(frac=1,random_state=0)\n",
    "dc_listings = dc_listings.sort_values('distance')\n",
    "dc_listings.price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在的问题是，这里面的数据是字符串呀，需要转换一下！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_listings['price'] = dc_listings.price.str.replace(\"\\$|,\",'').astype(float)\n",
    "\n",
    "mean_price = dc_listings.price.iloc[:5].mean()\n",
    "mean_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到了平均价格，也就是我们的房子大致的价格了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型的评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"7.png\" style=\"width:600px;height:250px;float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先制定好训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dc_listings.drop('distance',axis=1)\n",
    "\n",
    "train_df = dc_listings.copy().iloc[:2792]\n",
    "test_df = dc_listings.copy().iloc[2792:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于单变量预测价格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_price(new_listing_value,feature_column):\n",
    "    temp_df = train_df\n",
    "    temp_df['distance'] = np.abs(dc_listings[feature_column] - new_listing_value)\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    knn_5 = temp_df.price.iloc[:5]\n",
    "    predicted_price = knn_5.mean()\n",
    "    return(predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['predicted_price'] = test_df.accommodates.apply(predict_price,feature_column='accommodates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样我们就得到了测试集中，所以房子的价格了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "root mean squared error (RMSE)均方根误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"8.png\" style=\"width:700px;height:100px;float:left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.98927967051543"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['squared_error'] = (test_df['predicted_price'] - test_df['price'])**(2)\n",
    "mse = test_df['squared_error'].mean()\n",
    "rmse = mse ** (1/2)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们得到了对于一个变量的模型评估得分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同的变量效果会不会不同呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for the accommodates column: 212.98927967051543\n",
      "RMSE for the bedrooms column: 199.80935328065033\n",
      "RMSE for the bathrooms column: 230.24716705684227\n",
      "RMSE for the number_of_reviews column: 235.91327066995507\n"
     ]
    }
   ],
   "source": [
    "for feature in ['accommodates','bedrooms','bathrooms','number_of_reviews']:\n",
    "    #test_df['predicted_price'] = test_df.accommodates.apply(predict_price,feature_column=feature)\n",
    "    test_df['predicted_price'] = test_df[feature].apply(predict_price,feature_column=feature)\n",
    "    test_df['squared_error'] = (test_df['predicted_price'] - test_df['price'])**(2)\n",
    "    mse = test_df['squared_error'].mean()\n",
    "    rmse = mse ** (1/2)\n",
    "    print(\"RMSE for the {} column: {}\".format(feature,rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看起来结果差异还是蛮大的，接下来我们要做的就是综合利用所有的信息来一起进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3671, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.401420</td>\n",
       "      <td>-0.249501</td>\n",
       "      <td>-0.439211</td>\n",
       "      <td>0.297386</td>\n",
       "      <td>0.081119</td>\n",
       "      <td>-0.341421</td>\n",
       "      <td>-0.016575</td>\n",
       "      <td>-0.516779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.399466</td>\n",
       "      <td>2.129508</td>\n",
       "      <td>2.969551</td>\n",
       "      <td>1.141704</td>\n",
       "      <td>1.462622</td>\n",
       "      <td>-0.065047</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>1.706767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.095648</td>\n",
       "      <td>-0.249501</td>\n",
       "      <td>1.265170</td>\n",
       "      <td>-0.546933</td>\n",
       "      <td>-0.718699</td>\n",
       "      <td>-0.065047</td>\n",
       "      <td>-0.016575</td>\n",
       "      <td>-0.482571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.596625</td>\n",
       "      <td>-0.249501</td>\n",
       "      <td>-0.439211</td>\n",
       "      <td>-0.546933</td>\n",
       "      <td>-0.391501</td>\n",
       "      <td>-0.341421</td>\n",
       "      <td>-0.016575</td>\n",
       "      <td>-0.516779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.401420</td>\n",
       "      <td>-0.249501</td>\n",
       "      <td>-0.439211</td>\n",
       "      <td>-0.546933</td>\n",
       "      <td>-0.718699</td>\n",
       "      <td>1.316824</td>\n",
       "      <td>-0.016575</td>\n",
       "      <td>-0.516779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accommodates  bedrooms  bathrooms      beds     price  minimum_nights  \\\n",
       "0      0.401420 -0.249501  -0.439211  0.297386  0.081119       -0.341421   \n",
       "1      1.399466  2.129508   2.969551  1.141704  1.462622       -0.065047   \n",
       "2     -1.095648 -0.249501   1.265170 -0.546933 -0.718699       -0.065047   \n",
       "3     -0.596625 -0.249501  -0.439211 -0.546933 -0.391501       -0.341421   \n",
       "4      0.401420 -0.249501  -0.439211 -0.546933 -0.718699        1.316824   \n",
       "\n",
       "   maximum_nights  number_of_reviews  \n",
       "0       -0.016575          -0.516779  \n",
       "1       -0.016606           1.706767  \n",
       "2       -0.016575          -0.482571  \n",
       "3       -0.016575          -0.516779  \n",
       "4       -0.016575          -0.516779  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "features = ['accommodates','bedrooms','bathrooms','beds','price','minimum_nights','maximum_nights','number_of_reviews']\n",
    "\n",
    "dc_listings = pd.read_csv('listings.csv')\n",
    "\n",
    "dc_listings = dc_listings[features]\n",
    "\n",
    "dc_listings['price'] = dc_listings.price.str.replace(\"\\$|,\",'').astype(float)\n",
    "\n",
    "dc_listings = dc_listings.dropna()\n",
    "\n",
    "dc_listings[features] = StandardScaler().fit_transform(dc_listings[features])\n",
    "\n",
    "normalized_listings = dc_listings\n",
    "\n",
    "print(dc_listings.shape)\n",
    "\n",
    "normalized_listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_train_df = normalized_listings.copy().iloc[0:2792]\n",
    "norm_test_df = normalized_listings.copy().iloc[2792:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多变量距离的计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"9.png\" style=\"width:700px;height:400px;float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scipy中已经有现成的距离的计算工具了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.723019604017032"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "first_listing = normalized_listings.iloc[0][['accommodates', 'bathrooms']]\n",
    "fifth_listing = normalized_listings.iloc[20][['accommodates', 'bathrooms']]\n",
    "first_fifth_distance = distance.euclidean(first_listing, fifth_listing)\n",
    "first_fifth_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多变量KNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7894063922577537\n"
     ]
    }
   ],
   "source": [
    "def predict_price_multivariate(new_listing_value,feature_columns):\n",
    "    temp_df = norm_train_df\n",
    "    temp_df['distance'] = distance.cdist(temp_df[feature_columns],[new_listing_value[feature_columns]])\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    knn_5 = temp_df.price.iloc[:5]\n",
    "    predicted_price = knn_5.mean()\n",
    "    return(predicted_price)\n",
    "\n",
    "cols = ['accommodates', 'bathrooms']\n",
    "norm_test_df['predicted_price'] = norm_test_df[cols].apply(predict_price_multivariate,feature_columns=cols,axis=1)    \n",
    "norm_test_df['squared_error'] = (norm_test_df['predicted_price'] - norm_test_df['price'])**(2)\n",
    "mse = norm_test_df['squared_error'].mean()\n",
    "rmse = mse ** (1/2)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Sklearn来完成KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "cols = ['accommodates','bedrooms']\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(norm_train_df[cols], norm_train_df['price'])\n",
    "two_features_predictions = knn.predict(norm_test_df[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842682470482\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "two_features_mse = mean_squared_error(norm_test_df['price'], two_features_predictions)\n",
    "two_features_rmse = two_features_mse ** (1/2)\n",
    "print(two_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入更多的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82438385308802853"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "\n",
    "cols = ['accommodates','bedrooms','bathrooms','beds','minimum_nights','maximum_nights','number_of_reviews']\n",
    "\n",
    "knn.fit(norm_train_df[cols], norm_train_df['price'])\n",
    "four_features_predictions = knn.predict(norm_test_df[cols])\n",
    "four_features_mse = mean_squared_error(norm_test_df['price'], four_features_predictions)\n",
    "four_features_rmse = four_features_mse ** (1/2)\n",
    "four_features_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
